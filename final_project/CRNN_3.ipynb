{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main\n",
    "import os\n",
    "import gc\n",
    "import shutil\n",
    "import time\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import glob\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "import re\n",
    "\n",
    "# Data Visualization\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import plotly\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "from plotly.subplots import make_subplots\n",
    "from IPython.display import Image, display\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms,models\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "import string\n",
    "from tqdm.notebook import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import multiprocessing as mp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "provinces = [\"皖\", \"沪\", \"津\", \"渝\", \"冀\", \"晋\", \"蒙\", \"辽\", \"吉\", \"黑\", \"苏\", \"浙\", \"京\", \"闽\", \"赣\", \"鲁\", \"豫\", \"鄂\", \"湘\", \"粤\", \"桂\", \"琼\", \"川\", \"贵\", \"云\", \"藏\", \"陕\", \"甘\", \"青\", \"宁\", \"新\", \"警\", \"学\", \"O\"]\n",
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O']\n",
    "ads = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X',\n",
    "       'Y', 'Z', '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'O']\n",
    "\n",
    "# list_sub = [\"ccpd_base\", \"ccpd_fn\", \"ccpd_db\", \"ccpd_rotate\", \"ccpd_weather\", \"ccpd_blur\"]\n",
    "list_sub = [\"ccpd_weather\"]\n",
    "BASE_PATH = \"C:/Users/User/DeepLearning/Deep_Learning/final_project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>decode_plate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>294</td>\n",
       "      <td>496</td>\n",
       "      <td>374</td>\n",
       "      <td>540</td>\n",
       "      <td>皖AD130W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>304</td>\n",
       "      <td>542</td>\n",
       "      <td>411</td>\n",
       "      <td>577</td>\n",
       "      <td>皖AUT267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>339</td>\n",
       "      <td>547</td>\n",
       "      <td>444</td>\n",
       "      <td>583</td>\n",
       "      <td>皖MZ4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>177</td>\n",
       "      <td>511</td>\n",
       "      <td>268</td>\n",
       "      <td>553</td>\n",
       "      <td>皖AVD028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>402</td>\n",
       "      <td>426</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>皖RL222P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>89</td>\n",
       "      <td>832</td>\n",
       "      <td>500</td>\n",
       "      <td>1159</td>\n",
       "      <td>皖AK927W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>81</td>\n",
       "      <td>357</td>\n",
       "      <td>572</td>\n",
       "      <td>632</td>\n",
       "      <td>皖A22T99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>245</td>\n",
       "      <td>391</td>\n",
       "      <td>703</td>\n",
       "      <td>692</td>\n",
       "      <td>皖NRX399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>69</td>\n",
       "      <td>394</td>\n",
       "      <td>681</td>\n",
       "      <td>620</td>\n",
       "      <td>皖EW666K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>31</td>\n",
       "      <td>397</td>\n",
       "      <td>673</td>\n",
       "      <td>624</td>\n",
       "      <td>皖AWP202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path   x1   y1   x2    y2  \\\n",
       "0     C:/Users/User/DeepLearning/Deep_Learning/final...  294  496  374   540   \n",
       "1     C:/Users/User/DeepLearning/Deep_Learning/final...  304  542  411   577   \n",
       "2     C:/Users/User/DeepLearning/Deep_Learning/final...  339  547  444   583   \n",
       "3     C:/Users/User/DeepLearning/Deep_Learning/final...  177  511  268   553   \n",
       "4     C:/Users/User/DeepLearning/Deep_Learning/final...  402  426  497   467   \n",
       "...                                                 ...  ...  ...  ...   ...   \n",
       "9994  C:/Users/User/DeepLearning/Deep_Learning/final...   89  832  500  1159   \n",
       "9995  C:/Users/User/DeepLearning/Deep_Learning/final...   81  357  572   632   \n",
       "9996  C:/Users/User/DeepLearning/Deep_Learning/final...  245  391  703   692   \n",
       "9997  C:/Users/User/DeepLearning/Deep_Learning/final...   69  394  681   620   \n",
       "9998  C:/Users/User/DeepLearning/Deep_Learning/final...   31  397  673   624   \n",
       "\n",
       "     decode_plate  \n",
       "0         皖AD130W  \n",
       "1         皖AUT267  \n",
       "2         皖MZ4882  \n",
       "3         皖AVD028  \n",
       "4         皖RL222P  \n",
       "...           ...  \n",
       "9994      皖AK927W  \n",
       "9995      皖A22T99  \n",
       "9996      皖NRX399  \n",
       "9997      皖EW666K  \n",
       "9998      皖AWP202  \n",
       "\n",
       "[9999 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img_path = []\n",
    "left_up_x = []\n",
    "left_up_y = []\n",
    "right_down_x = []\n",
    "right_down_y = []\n",
    "decoded_plate = []\n",
    "location = []\n",
    "license_images = []\n",
    "for sub in list_sub:\n",
    "    sub_path = os.path.join(BASE_PATH, sub)\n",
    "    sub_files = glob.glob(os.path.join(sub_path, \"*\"))\n",
    "\n",
    "    for file in sub_files:\n",
    "\n",
    "        img_path.append(file)\n",
    "\n",
    "        file_no_jpg = file.split(\"/\")[-1][:-4]\n",
    "\n",
    "        boundind_box = file_no_jpg.split(\"-\")[2]\n",
    "        left_up_bbox = boundind_box.split(\"_\")[0]\n",
    "        right_down_bbox = boundind_box.split(\"_\")[1]\n",
    "        left_up_x .append(left_up_bbox.split(\",\")[0])\n",
    "        left_up_y .append(left_up_bbox.split(\",\")[1])\n",
    "        right_down_x .append(right_down_bbox.split(\",\")[0])\n",
    "        right_down_y .append(right_down_bbox.split(\",\")[1])\n",
    "\n",
    "\n",
    "\n",
    "        temp = []\n",
    "        plate_number =  file_no_jpg.split(\"-\")[-3]\n",
    "        plate_number_split =  plate_number.split('_')\n",
    "        city = provinces[int(plate_number_split[0])]\n",
    "        alp = alphabets[int(plate_number_split[1])]\n",
    "        temp.append(city)\n",
    "        temp.append(alp)\n",
    "        \n",
    "        for i in range(len(plate_number_split)-2):\n",
    "            temp.append(ads[int(plate_number_split[i+2])])\n",
    "        k = \"\".join(temp)\n",
    "        decoded_plate.append(k)\n",
    "\n",
    "\n",
    "        # exver_img = cv2.imread(file)\n",
    "        # vertices = file_no_jpg.split(\"-\")[3]\n",
    "        # split = vertices.split(\"_\")\n",
    "\n",
    "        # x= (split[0].split(','))\n",
    "        # y= (split[1].split(','))\n",
    "        # z= (split[2].split(','))\n",
    "        # w= (split[3].split(','))\n",
    "        # coordinates= [int(x[0]), int(x[1]),int(y[0]),int(y[1]),int(z[0]),int(z[1]),int(w[0]),int(w[1])]\n",
    "        # location.append(coordinates)\n",
    "        # p1 = np.float32([[coordinates[4], coordinates[5]],\n",
    "        #                 [coordinates[6], coordinates[7]],\n",
    "        #                 [coordinates[2], coordinates[3]], \n",
    "        #                 [coordinates[0], coordinates[1]]])\n",
    "        # p2 = np.float32([[0, 0],[exver_img.shape[1],0],[0,exver_img.shape[0]],[exver_img.shape[1],exver_img.shape[0]]])\n",
    "        # M = cv2.getPerspectiveTransform(p1, p2)\n",
    "        # outimg = cv2.warpPerspective(exver_img, M, exver_img.shape[1::-1])\n",
    "        # resized = cv2.resize(outimg, (120,24), interpolation = cv2.INTER_AREA)\n",
    "        # no_chinese_img = resized[:,width//8:]\n",
    "        # license_images.append(resized)\n",
    "        \n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "r = [img_path,left_up_x,left_up_y,right_down_x,right_down_y,decoded_plate]\n",
    "all_data = pd.DataFrame(r)\n",
    "all_data = all_data.T\n",
    "all_data.columns = ['img_path','x1','y1','x2','y2','decode_plate']\n",
    "all_data                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>decode_plate</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>294</td>\n",
       "      <td>496</td>\n",
       "      <td>374</td>\n",
       "      <td>540</td>\n",
       "      <td>皖AD130W</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>304</td>\n",
       "      <td>542</td>\n",
       "      <td>411</td>\n",
       "      <td>577</td>\n",
       "      <td>皖AUT267</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>339</td>\n",
       "      <td>547</td>\n",
       "      <td>444</td>\n",
       "      <td>583</td>\n",
       "      <td>皖MZ4882</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>177</td>\n",
       "      <td>511</td>\n",
       "      <td>268</td>\n",
       "      <td>553</td>\n",
       "      <td>皖AVD028</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>402</td>\n",
       "      <td>426</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>皖RL222P</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>89</td>\n",
       "      <td>832</td>\n",
       "      <td>500</td>\n",
       "      <td>1159</td>\n",
       "      <td>皖AK927W</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>81</td>\n",
       "      <td>357</td>\n",
       "      <td>572</td>\n",
       "      <td>632</td>\n",
       "      <td>皖A22T99</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>245</td>\n",
       "      <td>391</td>\n",
       "      <td>703</td>\n",
       "      <td>692</td>\n",
       "      <td>皖NRX399</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>69</td>\n",
       "      <td>394</td>\n",
       "      <td>681</td>\n",
       "      <td>620</td>\n",
       "      <td>皖EW666K</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>31</td>\n",
       "      <td>397</td>\n",
       "      <td>673</td>\n",
       "      <td>624</td>\n",
       "      <td>皖AWP202</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path   x1   y1   x2    y2  \\\n",
       "0     C:/Users/User/DeepLearning/Deep_Learning/final...  294  496  374   540   \n",
       "1     C:/Users/User/DeepLearning/Deep_Learning/final...  304  542  411   577   \n",
       "2     C:/Users/User/DeepLearning/Deep_Learning/final...  339  547  444   583   \n",
       "3     C:/Users/User/DeepLearning/Deep_Learning/final...  177  511  268   553   \n",
       "4     C:/Users/User/DeepLearning/Deep_Learning/final...  402  426  497   467   \n",
       "...                                                 ...  ...  ...  ...   ...   \n",
       "9994  C:/Users/User/DeepLearning/Deep_Learning/final...   89  832  500  1159   \n",
       "9995  C:/Users/User/DeepLearning/Deep_Learning/final...   81  357  572   632   \n",
       "9996  C:/Users/User/DeepLearning/Deep_Learning/final...  245  391  703   692   \n",
       "9997  C:/Users/User/DeepLearning/Deep_Learning/final...   69  394  681   620   \n",
       "9998  C:/Users/User/DeepLearning/Deep_Learning/final...   31  397  673   624   \n",
       "\n",
       "     decode_plate  split  \n",
       "0         皖AD130W  train  \n",
       "1         皖AUT267  train  \n",
       "2         皖MZ4882  train  \n",
       "3         皖AVD028  train  \n",
       "4         皖RL222P  train  \n",
       "...           ...    ...  \n",
       "9994      皖AK927W   test  \n",
       "9995      皖A22T99   test  \n",
       "9996      皖NRX399   test  \n",
       "9997      皖EW666K   test  \n",
       "9998      皖AWP202   test  \n",
       "\n",
       "[9999 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_split = [\"train\"] * 9499\n",
    "for i in range(5):\n",
    "    list_split.extend([\"val\"]*50)\n",
    "    list_split.extend([\"test\"]*50)\n",
    "all_data [\"split\"] = list_split\n",
    "all_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>decode_plate</th>\n",
       "      <th>split</th>\n",
       "      <th>no_chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>294</td>\n",
       "      <td>496</td>\n",
       "      <td>374</td>\n",
       "      <td>540</td>\n",
       "      <td>皖AD130W</td>\n",
       "      <td>train</td>\n",
       "      <td>AD130W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>304</td>\n",
       "      <td>542</td>\n",
       "      <td>411</td>\n",
       "      <td>577</td>\n",
       "      <td>皖AUT267</td>\n",
       "      <td>train</td>\n",
       "      <td>AUT267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>339</td>\n",
       "      <td>547</td>\n",
       "      <td>444</td>\n",
       "      <td>583</td>\n",
       "      <td>皖MZ4882</td>\n",
       "      <td>train</td>\n",
       "      <td>MZ4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>177</td>\n",
       "      <td>511</td>\n",
       "      <td>268</td>\n",
       "      <td>553</td>\n",
       "      <td>皖AVD028</td>\n",
       "      <td>train</td>\n",
       "      <td>AVD028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>402</td>\n",
       "      <td>426</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>皖RL222P</td>\n",
       "      <td>train</td>\n",
       "      <td>RL222P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9994</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>89</td>\n",
       "      <td>832</td>\n",
       "      <td>500</td>\n",
       "      <td>1159</td>\n",
       "      <td>皖AK927W</td>\n",
       "      <td>test</td>\n",
       "      <td>AK927W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>81</td>\n",
       "      <td>357</td>\n",
       "      <td>572</td>\n",
       "      <td>632</td>\n",
       "      <td>皖A22T99</td>\n",
       "      <td>test</td>\n",
       "      <td>A22T99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>245</td>\n",
       "      <td>391</td>\n",
       "      <td>703</td>\n",
       "      <td>692</td>\n",
       "      <td>皖NRX399</td>\n",
       "      <td>test</td>\n",
       "      <td>NRX399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>69</td>\n",
       "      <td>394</td>\n",
       "      <td>681</td>\n",
       "      <td>620</td>\n",
       "      <td>皖EW666K</td>\n",
       "      <td>test</td>\n",
       "      <td>EW666K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>31</td>\n",
       "      <td>397</td>\n",
       "      <td>673</td>\n",
       "      <td>624</td>\n",
       "      <td>皖AWP202</td>\n",
       "      <td>test</td>\n",
       "      <td>AWP202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9999 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path   x1   y1   x2    y2  \\\n",
       "0     C:/Users/User/DeepLearning/Deep_Learning/final...  294  496  374   540   \n",
       "1     C:/Users/User/DeepLearning/Deep_Learning/final...  304  542  411   577   \n",
       "2     C:/Users/User/DeepLearning/Deep_Learning/final...  339  547  444   583   \n",
       "3     C:/Users/User/DeepLearning/Deep_Learning/final...  177  511  268   553   \n",
       "4     C:/Users/User/DeepLearning/Deep_Learning/final...  402  426  497   467   \n",
       "...                                                 ...  ...  ...  ...   ...   \n",
       "9994  C:/Users/User/DeepLearning/Deep_Learning/final...   89  832  500  1159   \n",
       "9995  C:/Users/User/DeepLearning/Deep_Learning/final...   81  357  572   632   \n",
       "9996  C:/Users/User/DeepLearning/Deep_Learning/final...  245  391  703   692   \n",
       "9997  C:/Users/User/DeepLearning/Deep_Learning/final...   69  394  681   620   \n",
       "9998  C:/Users/User/DeepLearning/Deep_Learning/final...   31  397  673   624   \n",
       "\n",
       "     decode_plate  split no_chinese  \n",
       "0         皖AD130W  train     AD130W  \n",
       "1         皖AUT267  train     AUT267  \n",
       "2         皖MZ4882  train     MZ4882  \n",
       "3         皖AVD028  train     AVD028  \n",
       "4         皖RL222P  train     RL222P  \n",
       "...           ...    ...        ...  \n",
       "9994      皖AK927W   test     AK927W  \n",
       "9995      皖A22T99   test     A22T99  \n",
       "9996      皖NRX399   test     NRX399  \n",
       "9997      皖EW666K   test     EW666K  \n",
       "9998      皖AWP202   test     AWP202  \n",
       "\n",
       "[9999 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_chinese = []\n",
    "for i in range(9999):\n",
    "    no_chinese.append(all_data['decode_plate'][i][1:])\n",
    "\n",
    "all_data['no_chinese'] = no_chinese\n",
    "all_data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>decode_plate</th>\n",
       "      <th>no_chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>294</td>\n",
       "      <td>496</td>\n",
       "      <td>374</td>\n",
       "      <td>540</td>\n",
       "      <td>皖AD130W</td>\n",
       "      <td>AD130W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>304</td>\n",
       "      <td>542</td>\n",
       "      <td>411</td>\n",
       "      <td>577</td>\n",
       "      <td>皖AUT267</td>\n",
       "      <td>AUT267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>339</td>\n",
       "      <td>547</td>\n",
       "      <td>444</td>\n",
       "      <td>583</td>\n",
       "      <td>皖MZ4882</td>\n",
       "      <td>MZ4882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>177</td>\n",
       "      <td>511</td>\n",
       "      <td>268</td>\n",
       "      <td>553</td>\n",
       "      <td>皖AVD028</td>\n",
       "      <td>AVD028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>402</td>\n",
       "      <td>426</td>\n",
       "      <td>497</td>\n",
       "      <td>467</td>\n",
       "      <td>皖RL222P</td>\n",
       "      <td>RL222P</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9494</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>179</td>\n",
       "      <td>440</td>\n",
       "      <td>595</td>\n",
       "      <td>575</td>\n",
       "      <td>皖AR8647</td>\n",
       "      <td>AR8647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9495</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>190</td>\n",
       "      <td>506</td>\n",
       "      <td>572</td>\n",
       "      <td>653</td>\n",
       "      <td>皖A47039</td>\n",
       "      <td>A47039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9496</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>125</td>\n",
       "      <td>405</td>\n",
       "      <td>526</td>\n",
       "      <td>545</td>\n",
       "      <td>皖A4U877</td>\n",
       "      <td>A4U877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9497</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>290</td>\n",
       "      <td>482</td>\n",
       "      <td>680</td>\n",
       "      <td>626</td>\n",
       "      <td>皖AH790W</td>\n",
       "      <td>AH790W</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9498</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>189</td>\n",
       "      <td>470</td>\n",
       "      <td>591</td>\n",
       "      <td>610</td>\n",
       "      <td>皖A3R197</td>\n",
       "      <td>A3R197</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9499 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               img_path   x1   y1   x2   y2  \\\n",
       "0     C:/Users/User/DeepLearning/Deep_Learning/final...  294  496  374  540   \n",
       "1     C:/Users/User/DeepLearning/Deep_Learning/final...  304  542  411  577   \n",
       "2     C:/Users/User/DeepLearning/Deep_Learning/final...  339  547  444  583   \n",
       "3     C:/Users/User/DeepLearning/Deep_Learning/final...  177  511  268  553   \n",
       "4     C:/Users/User/DeepLearning/Deep_Learning/final...  402  426  497  467   \n",
       "...                                                 ...  ...  ...  ...  ...   \n",
       "9494  C:/Users/User/DeepLearning/Deep_Learning/final...  179  440  595  575   \n",
       "9495  C:/Users/User/DeepLearning/Deep_Learning/final...  190  506  572  653   \n",
       "9496  C:/Users/User/DeepLearning/Deep_Learning/final...  125  405  526  545   \n",
       "9497  C:/Users/User/DeepLearning/Deep_Learning/final...  290  482  680  626   \n",
       "9498  C:/Users/User/DeepLearning/Deep_Learning/final...  189  470  591  610   \n",
       "\n",
       "     decode_plate no_chinese  \n",
       "0         皖AD130W     AD130W  \n",
       "1         皖AUT267     AUT267  \n",
       "2         皖MZ4882     MZ4882  \n",
       "3         皖AVD028     AVD028  \n",
       "4         皖RL222P     RL222P  \n",
       "...           ...        ...  \n",
       "9494      皖AR8647     AR8647  \n",
       "9495      皖A47039     A47039  \n",
       "9496      皖A4U877     A4U877  \n",
       "9497      皖AH790W     AH790W  \n",
       "9498      皖A3R197     A3R197  \n",
       "\n",
       "[9499 rows x 7 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = all_data [all_data[\"split\"]==\"train\"].reset_index(drop=True)\n",
    "df_train = df_train[[\"img_path\", \"x1\", \"y1\", \"x2\", \"y2\",\"decode_plate\",'no_chinese']]\n",
    "df_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>img_path</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>x2</th>\n",
       "      <th>y2</th>\n",
       "      <th>decode_plate</th>\n",
       "      <th>no_chinese</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>217</td>\n",
       "      <td>448</td>\n",
       "      <td>475</td>\n",
       "      <td>666</td>\n",
       "      <td>皖AY6F46</td>\n",
       "      <td>AY6F46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>134</td>\n",
       "      <td>424</td>\n",
       "      <td>504</td>\n",
       "      <td>576</td>\n",
       "      <td>浙C096FU</td>\n",
       "      <td>C096FU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>54</td>\n",
       "      <td>394</td>\n",
       "      <td>380</td>\n",
       "      <td>567</td>\n",
       "      <td>沪C0C9U1</td>\n",
       "      <td>C0C9U1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>281</td>\n",
       "      <td>536</td>\n",
       "      <td>662</td>\n",
       "      <td>684</td>\n",
       "      <td>皖AY060V</td>\n",
       "      <td>AY060V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>162</td>\n",
       "      <td>445</td>\n",
       "      <td>586</td>\n",
       "      <td>578</td>\n",
       "      <td>皖ADB398</td>\n",
       "      <td>ADB398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>245</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>147</td>\n",
       "      <td>426</td>\n",
       "      <td>643</td>\n",
       "      <td>595</td>\n",
       "      <td>皖AL1U67</td>\n",
       "      <td>AL1U67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>199</td>\n",
       "      <td>362</td>\n",
       "      <td>533</td>\n",
       "      <td>613</td>\n",
       "      <td>皖AUL132</td>\n",
       "      <td>AUL132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>233</td>\n",
       "      <td>338</td>\n",
       "      <td>589</td>\n",
       "      <td>574</td>\n",
       "      <td>皖AFJ956</td>\n",
       "      <td>AFJ956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>94</td>\n",
       "      <td>424</td>\n",
       "      <td>601</td>\n",
       "      <td>592</td>\n",
       "      <td>皖AS661Z</td>\n",
       "      <td>AS661Z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>C:/Users/User/DeepLearning/Deep_Learning/final...</td>\n",
       "      <td>105</td>\n",
       "      <td>412</td>\n",
       "      <td>719</td>\n",
       "      <td>551</td>\n",
       "      <td>吉BTW976</td>\n",
       "      <td>BTW976</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>250 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              img_path   x1   y1   x2   y2  \\\n",
       "0    C:/Users/User/DeepLearning/Deep_Learning/final...  217  448  475  666   \n",
       "1    C:/Users/User/DeepLearning/Deep_Learning/final...  134  424  504  576   \n",
       "2    C:/Users/User/DeepLearning/Deep_Learning/final...   54  394  380  567   \n",
       "3    C:/Users/User/DeepLearning/Deep_Learning/final...  281  536  662  684   \n",
       "4    C:/Users/User/DeepLearning/Deep_Learning/final...  162  445  586  578   \n",
       "..                                                 ...  ...  ...  ...  ...   \n",
       "245  C:/Users/User/DeepLearning/Deep_Learning/final...  147  426  643  595   \n",
       "246  C:/Users/User/DeepLearning/Deep_Learning/final...  199  362  533  613   \n",
       "247  C:/Users/User/DeepLearning/Deep_Learning/final...  233  338  589  574   \n",
       "248  C:/Users/User/DeepLearning/Deep_Learning/final...   94  424  601  592   \n",
       "249  C:/Users/User/DeepLearning/Deep_Learning/final...  105  412  719  551   \n",
       "\n",
       "    decode_plate no_chinese  \n",
       "0        皖AY6F46     AY6F46  \n",
       "1        浙C096FU     C096FU  \n",
       "2        沪C0C9U1     C0C9U1  \n",
       "3        皖AY060V     AY060V  \n",
       "4        皖ADB398     ADB398  \n",
       "..           ...        ...  \n",
       "245      皖AL1U67     AL1U67  \n",
       "246      皖AUL132     AUL132  \n",
       "247      皖AFJ956     AFJ956  \n",
       "248      皖AS661Z     AS661Z  \n",
       "249      吉BTW976     BTW976  \n",
       "\n",
       "[250 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_val = all_data [all_data[\"split\"]==\"val\"].reset_index(drop=True)\n",
    "df_val = df_val[[\"img_path\", \"x1\", \"y1\", \"x2\", \"y2\",\"decode_plate\",'no_chinese']]\n",
    "df_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial GPU Usage\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  0% |\n",
      "GPU Usage after emptying the cache\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  0% |  2% |\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "from GPUtil import showUtilization as gpu_usage\n",
    "\n",
    "def free_gpu_cache():\n",
    "    print(\"Initial GPU Usage\")\n",
    "    gpu_usage()                             \n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    cuda.select_device(0)\n",
    "    cuda.close()\n",
    "    cuda.select_device(0)\n",
    "\n",
    "    print(\"GPU Usage after emptying the cache\")\n",
    "    gpu_usage()\n",
    "\n",
    "free_gpu_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df_train = dataframe\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_train)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        train_path = self.df_train[\"img_path\"][index]\n",
    "        file_no_jpg = train_path.split(\"/\")[-1][:-4]\n",
    "\n",
    "        exver_img = cv2.imread(train_path)\n",
    "        vertices = file_no_jpg.split(\"-\")[3]\n",
    "        split = vertices.split(\"_\")\n",
    "\n",
    "        x= (split[0].split(','))\n",
    "        y= (split[1].split(','))\n",
    "        z= (split[2].split(','))\n",
    "        w= (split[3].split(','))\n",
    "        coordinates= [int(x[0]), int(x[1]),int(y[0]),int(y[1]),int(z[0]),int(z[1]),int(w[0]),int(w[1])]\n",
    "        location.append(coordinates)\n",
    "        p1 = np.float32([[coordinates[4], coordinates[5]],\n",
    "                        [coordinates[6], coordinates[7]],\n",
    "                        [coordinates[2], coordinates[3]], \n",
    "                        [coordinates[0], coordinates[1]]])\n",
    "        p2 = np.float32([[0, 0],[exver_img.shape[1],0],[0,exver_img.shape[0]],[exver_img.shape[1],exver_img.shape[0]]])\n",
    "        M = cv2.getPerspectiveTransform(p1, p2)\n",
    "        outimg = cv2.warpPerspective(exver_img, M, exver_img.shape[1::-1])\n",
    "        resized = cv2.resize(outimg, (120,24), interpolation = cv2.INTER_AREA)\n",
    "        \n",
    "        no_chinese_img = resized[:,120//8:]\n",
    "\n",
    "        text = self.df_train[\"no_chinese\"][index]\n",
    "\n",
    "        # Apply transformations\n",
    "        transformed_image = self.transform(no_chinese_img)\n",
    "\n",
    "        return transformed_image, text\n",
    "\n",
    "    def transform(self, image):\n",
    "        transform_ops = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.Resize((50, 200)),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
    "        ])\n",
    "        return transform_ops(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "594\n"
     ]
    }
   ],
   "source": [
    "trainset = Dataset(df_train)\n",
    "valset =  Dataset(df_val)\n",
    "\n",
    "train_loader = DataLoader(trainset, batch_size=16, num_workers=0, shuffle=False)\n",
    "test_loader = DataLoader(valset, batch_size=16, num_workers=0, shuffle=False)\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 50, 200]) ('AD130W', 'AUT267', 'MZ4882', 'AVD028', 'RL222P', 'AGC276', 'AU0194', 'AC880Y', 'ATG568', 'A41476', 'AH8V95', 'ATV235', 'AJ7532', 'AE0901', 'QSW808', 'A93853')\n"
     ]
    }
   ],
   "source": [
    "image_batch, text_batch = next(iter(train_loader))\n",
    "print(image_batch.size(), text_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'J', 9: 'K', 10: 'L', 11: 'M', 12: 'N', 13: 'P', 14: 'Q', 15: 'R', 16: 'S', 17: 'T', 18: 'U', 19: 'V', 20: 'W', 21: 'X', 22: 'Y', 23: 'Z', 24: 'O', 25: '0', 26: '1', 27: '2', 28: '3', 29: '4', 30: '5', 31: '6', 32: '7', 33: '8', 34: '9'}\n",
      "{'A': 0, 'B': 1, 'C': 2, 'D': 3, 'E': 4, 'F': 5, 'G': 6, 'H': 7, 'J': 8, 'K': 9, 'L': 10, 'M': 11, 'N': 12, 'P': 13, 'Q': 14, 'R': 15, 'S': 16, 'T': 17, 'U': 18, 'V': 19, 'W': 20, 'X': 21, 'Y': 22, 'Z': 23, 'O': 24, '0': 25, '1': 26, '2': 27, '3': 28, '4': 29, '5': 30, '6': 31, '7': 32, '8': 33, '9': 34}\n"
     ]
    }
   ],
   "source": [
    "alphabets = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'J', 'K', 'L', 'M', 'N', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W',\n",
    "             'X', 'Y', 'Z', 'O','0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n",
    "idx2char = {k:v for k,v in enumerate(alphabets, start=0)}\n",
    "print(idx2char)\n",
    "char2idx = {v:k for k,v in idx2char.items()}\n",
    "print(char2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "num_chars = len(char2idx)\n",
    "print(num_chars)\n",
    "rnn_hidden_size = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Sequential(\n",
      "  (0): Conv2dNormActivation(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      "  (1): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (2): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
      "        (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (3): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (4): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
      "        (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (5): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (6): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (7): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
      "        (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (8): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (9): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (10): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (11): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
      "        (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (12): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (13): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (14): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
      "        (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (15): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (16): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (17): InvertedResidual(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2dNormActivation(\n",
      "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (1): Conv2dNormActivation(\n",
      "        (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
      "        (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU6(inplace=True)\n",
      "      )\n",
      "      (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "      (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    )\n",
      "  )\n",
      "  (18): Conv2dNormActivation(\n",
      "    (0): Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU6(inplace=True)\n",
      "  )\n",
      ")]\n"
     ]
    }
   ],
   "source": [
    "mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "for param in mobilenet.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "mobilenet.features[18][0] = nn.Conv2d(320, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
    "\n",
    "# Replace the BatchNorm2d layer\n",
    "mobilenet.features[18][1] = nn.BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
    "\n",
    "mobilenet_modules = list(mobilenet.children())[:-1]\n",
    "\n",
    "print(mobilenet_modules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "\n",
    "class CRNN(nn.Module):\n",
    "    \n",
    "    def __init__(self, num_chars, rnn_hidden_size=256, dropout=0.4):\n",
    "        \n",
    "        super(CRNN, self).__init__()\n",
    "        self.num_chars = num_chars\n",
    "        self.rnn_hidden_size = rnn_hidden_size\n",
    "        self.dropout = dropout\n",
    "\n",
    "        # MobileNetV2\n",
    "        # mobilenet = models.mobilenet_v2(pretrained=True)\n",
    "        # for param in mobilenet.parameters():\n",
    "        #     param.requires_grad = False\n",
    "\n",
    "        # mobilenet_modules = list(mobilenet.children())[:-1]\n",
    "        \n",
    "        # self.cnn = nn.Sequential(*mobilenet_modules)\n",
    "        self.conv =  nn.Conv2d(35, 256, kernel_size=(3,6), stride=1, padding=1) # Adjusted kernel_size\n",
    "        self.batch_norm = nn.BatchNorm2d(256)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        \n",
    "        # CNN Part 2\n",
    "        self.linear1 = nn.Linear(512, 256)  # Adjusted based on the expected output size from MobileNetV2\n",
    "        \n",
    "        # RNN\n",
    "        self.rnn = nn.GRU(input_size=256, hidden_size=rnn_hidden_size, bidirectional=True, batch_first=True)\n",
    "        self.linear2 = nn.Linear(self.rnn_hidden_size*2, num_chars)\n",
    "        \n",
    "    def forward(self, batch):\n",
    "        \n",
    "        # batch = self.cnn(batch)\n",
    "        # batch = F.interpolate(batch, size=(2, 13), mode='nearest')\n",
    "        # print(batch.size())\n",
    "        batch = self.conv(batch)\n",
    "        # print(batch.size())\n",
    "        batch = self.batch_norm(batch)\n",
    "        # print(batch.size())\n",
    "        batch = self.relu(batch)\n",
    "        # print(batch.size())\n",
    "        \n",
    "        batch = batch.permute(0, 3, 1, 2) \n",
    "        # print(batch.size())\n",
    "        batch_size = batch.size(0)\n",
    "        # print(batch.size())\n",
    "        T = batch.size(1)\n",
    "        batch = batch.view(batch_size, T, -1) \n",
    "        # print(batch.size())\n",
    "        batch = self.linear1(batch)\n",
    "        # print(batch.size())\n",
    "        \n",
    "        batch, hidden = self.rnn(batch)\n",
    "        # print(batch.size())\n",
    "        feature_size = batch.size(2)\n",
    "        batch = batch[:, :, :feature_size//2] + batch[:, :, feature_size//2:]\n",
    "        # print(batch.size())\n",
    "       \n",
    "        batch, hidden = self.rnn(batch)\n",
    "        # print(batch.size())\n",
    "        \n",
    "        batch = self.linear2(batch)\n",
    "        # print(batch.size())\n",
    "        \n",
    "        batch = batch.permute(1, 0, 2)\n",
    "        # print(batch.size())\n",
    "        \n",
    "        \n",
    "\n",
    "# Upsample the tensor\n",
    "        \n",
    "        return batch\n",
    "\n",
    "# Rest of your code remains the same...\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if type(m) in [nn.Linear, nn.Conv2d, nn.Conv1d]:\n",
    "        torch.nn.init.xavier_uniform_(m.weight)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0.01)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        m.weight.data.normal_(1.0, 0.02)\n",
    "        m.bias.data.fill_(0)\n",
    "\n",
    "    # ... (rest of your weights_init function)\n",
    "\n",
    "crnn = CRNN(num_chars, rnn_hidden_size=rnn_hidden_size)\n",
    "crnn.apply(weights_init)\n",
    "crnn = crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [256, 35, 3, 6], expected input[16, 3, 50, 200] to have 35 channels, but got 3 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[179], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m text_batch_logits \u001b[38;5;241m=\u001b[39m \u001b[43mcrnn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage_batch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_batch)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(text_batch_logits\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[178], line 37\u001b[0m, in \u001b[0;36mCRNN.forward\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch):\n\u001b[0;32m     33\u001b[0m     \n\u001b[0;32m     34\u001b[0m     \u001b[38;5;66;03m# batch = self.cnn(batch)\u001b[39;00m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;66;03m# batch = F.interpolate(batch, size=(2, 13), mode='nearest')\u001b[39;00m\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# print(batch.size())\u001b[39;00m\n\u001b[1;32m---> 37\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m     \u001b[38;5;66;03m# print(batch.size())\u001b[39;00m\n\u001b[0;32m     39\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_norm(batch)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:460\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 460\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:456\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    452\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv2d(F\u001b[38;5;241m.\u001b[39mpad(\u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode),\n\u001b[0;32m    454\u001b[0m                     weight, bias, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstride,\n\u001b[0;32m    455\u001b[0m                     _pair(\u001b[38;5;241m0\u001b[39m), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdilation, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups)\n\u001b[1;32m--> 456\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv2d\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Given groups=1, weight of size [256, 35, 3, 6], expected input[16, 3, 50, 200] to have 35 channels, but got 3 channels instead"
     ]
    }
   ],
   "source": [
    "text_batch_logits = crnn(image_batch.to(device))\n",
    "print(text_batch)\n",
    "print(text_batch_logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CTCLoss(blank=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.5867, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def encode_text_batch(text_batch):\n",
    "    \n",
    "    text_batch_targets_lens = [len(text) for text in text_batch]\n",
    "    text_batch_targets_lens = torch.IntTensor(text_batch_targets_lens)\n",
    "    \n",
    "    text_batch_concat = \"\".join(text_batch)\n",
    "    text_batch_targets = [char2idx[c] for c in text_batch_concat]\n",
    "    text_batch_targets = torch.IntTensor(text_batch_targets)\n",
    "    \n",
    "    return text_batch_targets, text_batch_targets_lens\n",
    "def compute_loss(text_batch, text_batch_logits):\n",
    "    \"\"\"\n",
    "    text_batch: list of strings of length equal to batch size\n",
    "    text_batch_logits: Tensor of size([T, batch_size, num_classes])\n",
    "    \"\"\"\n",
    "    text_batch_logps = F.log_softmax(text_batch_logits, 2) # [T, batch_size, num_classes]  \n",
    "    text_batch_logps_lens = torch.full(size=(text_batch_logps.size(1),), \n",
    "                                       fill_value=text_batch_logps.size(0), \n",
    "                                       dtype=torch.int32).to(device) # [batch_size] \n",
    "    \n",
    "    text_batch_targets, text_batch_targets_lens = encode_text_batch(text_batch)\n",
    "    \n",
    "    loss = criterion(text_batch_logps, text_batch_targets, text_batch_logps_lens, text_batch_targets_lens)\n",
    "\n",
    "    return loss\n",
    "\n",
    "compute_loss(text_batch, text_batch_logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "lr = 0.001\n",
    "weight_decay = 1e-3\n",
    "clip_norm = 5\n",
    "\n",
    "optimizer = optim.Adam(crnn.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "lr_scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, verbose=True, patience=5)\n",
    "\n",
    "\n",
    "crnn = CRNN(num_chars, rnn_hidden_size=rnn_hidden_size)\n",
    "crnn.apply(weights_init)\n",
    "crnn = crnn.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbc95934bf254c18a20d817e72b9d3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ec731550229428688eae57c72ee3b88",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:1    Loss:4.5947730621504865    NumUpdates:594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6395d6bee0d41caab53e22273fc11b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:2    Loss:4.5947730621504865    NumUpdates:594\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4396ac5856040f3a5b29c77092c2593",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/594 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[175], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m epoch_loss_list \u001b[38;5;241m=\u001b[39m [] \n\u001b[0;32m      6\u001b[0m num_updates_epoch \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m image_batch, text_batch \u001b[38;5;129;01min\u001b[39;00m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m      8\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m      9\u001b[0m     text_batch_logits \u001b[38;5;241m=\u001b[39m crnn(image_batch\u001b[38;5;241m.\u001b[39mto(device))\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\tqdm\\notebook.py:249\u001b[0m, in \u001b[0;36mtqdm_notebook.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    248\u001b[0m     it \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m(tqdm_notebook, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__iter__\u001b[39m()\n\u001b[1;32m--> 249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m it:\n\u001b[0;32m    250\u001b[0m         \u001b[38;5;66;03m# return super(tqdm...) will not catch exception\u001b[39;00m\n\u001b[0;32m    251\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m    252\u001b[0m \u001b[38;5;66;03m# NB: except ... [ as ...] breaks IPython async KeyboardInterrupt\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\tqdm\\std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1179\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[0;32m   1181\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1182\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[0;32m   1183\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[0;32m   1184\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1185\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[109], line 36\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, index)\u001b[0m\n\u001b[0;32m     33\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_train[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mno_chinese\u001b[39m\u001b[38;5;124m\"\u001b[39m][index]\n\u001b[0;32m     35\u001b[0m \u001b[38;5;66;03m# Apply transformations\u001b[39;00m\n\u001b[1;32m---> 36\u001b[0m transformed_image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mno_chinese_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m transformed_image, text\n",
      "Cell \u001b[1;32mIn[109], line 47\u001b[0m, in \u001b[0;36mDataset.transform\u001b[1;34m(self, image)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(\u001b[38;5;28mself\u001b[39m, image):\n\u001b[0;32m     41\u001b[0m     transform_ops \u001b[38;5;241m=\u001b[39m transforms\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m     42\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToPILImage(),\n\u001b[0;32m     43\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mResize((\u001b[38;5;241m50\u001b[39m, \u001b[38;5;241m200\u001b[39m)),\n\u001b[0;32m     44\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m     45\u001b[0m         transforms\u001b[38;5;241m.\u001b[39mNormalize(mean\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.485\u001b[39m, \u001b[38;5;241m0.456\u001b[39m, \u001b[38;5;241m0.406\u001b[39m), std\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0.229\u001b[39m, \u001b[38;5;241m0.224\u001b[39m, \u001b[38;5;241m0.225\u001b[39m))\n\u001b[0;32m     46\u001b[0m     ])\n\u001b[1;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtransform_ops\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[38;5;241m=\u001b[39m \u001b[43mt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     96\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:361\u001b[0m, in \u001b[0;36mResize.forward\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m    353\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, img):\n\u001b[0;32m    354\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    355\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    356\u001b[0m \u001b[38;5;124;03m        img (PIL Image or Tensor): Image to be scaled.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    359\u001b[0m \u001b[38;5;124;03m        PIL Image or Tensor: Rescaled image.\u001b[39;00m\n\u001b[0;32m    360\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 361\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mantialias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\transforms\\functional.py:490\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[0;32m    488\u001b[0m         warnings\u001b[38;5;241m.\u001b[39mwarn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnti-alias option is always applied for PIL Image input. Argument antialias is ignored.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    489\u001b[0m     pil_interpolation \u001b[38;5;241m=\u001b[39m pil_modes_mapping[interpolation]\n\u001b[1;32m--> 490\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_pil\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_interpolation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    492\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m F_t\u001b[38;5;241m.\u001b[39mresize(img, size\u001b[38;5;241m=\u001b[39moutput_size, interpolation\u001b[38;5;241m=\u001b[39minterpolation\u001b[38;5;241m.\u001b[39mvalue, antialias\u001b[38;5;241m=\u001b[39mantialias)\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\torchvision\\transforms\\_functional_pil.py:250\u001b[0m, in \u001b[0;36mresize\u001b[1;34m(img, size, interpolation)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(size, \u001b[38;5;28mlist\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(size) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m    248\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot inappropriate size arg: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msize\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 250\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\User\\anaconda3\\envs\\DeepLearning\\Lib\\site-packages\\PIL\\Image.py:2199\u001b[0m, in \u001b[0;36mImage.resize\u001b[1;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[0;32m   2191\u001b[0m             \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mreduce(\u001b[38;5;28mself\u001b[39m, factor, box\u001b[38;5;241m=\u001b[39mreduce_box)\n\u001b[0;32m   2192\u001b[0m         box \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2193\u001b[0m             (box[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2194\u001b[0m             (box[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2195\u001b[0m             (box[\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m0\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_x,\n\u001b[0;32m   2196\u001b[0m             (box[\u001b[38;5;241m3\u001b[39m] \u001b[38;5;241m-\u001b[39m reduce_box[\u001b[38;5;241m1\u001b[39m]) \u001b[38;5;241m/\u001b[39m factor_y,\n\u001b[0;32m   2197\u001b[0m         )\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresize\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbox\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epoch_losses = []\n",
    "iteration_losses = []\n",
    "num_updates_epochs = []\n",
    "for epoch in tqdm(range(1, num_epochs+1)):\n",
    "    epoch_loss_list = [] \n",
    "    num_updates_epoch = 0\n",
    "    for image_batch, text_batch in tqdm(train_loader, leave=False):\n",
    "        optimizer.zero_grad()\n",
    "        text_batch_logits = crnn(image_batch.to(device))\n",
    "        loss = compute_loss(text_batch, text_batch_logits)\n",
    "        iteration_loss = loss.item()\n",
    "\n",
    "        if np.isnan(iteration_loss) or np.isinf(iteration_loss):\n",
    "            continue\n",
    "          \n",
    "        num_updates_epoch += 1\n",
    "        iteration_losses.append(iteration_loss)\n",
    "        epoch_loss_list.append(iteration_loss)\n",
    "        loss.backward()\n",
    "        nn.utils.clip_grad_norm_(crnn.parameters(), clip_norm)\n",
    "        optimizer.step()\n",
    "\n",
    "    epoch_loss = np.mean(epoch_loss_list)\n",
    "    print(\"Epoch:{}    Loss:{}    NumUpdates:{}\".format(epoch, epoch_loss, num_updates_epoch))\n",
    "    epoch_losses.append(epoch_loss)\n",
    "    num_updates_epochs.append(num_updates_epoch)\n",
    "    lr_scheduler.step(epoch_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(crnn.state_dict(), 'crnn_no_chinese_model_3.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRNN(\n",
       "  (cnn_p1): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (cnn_p2): Sequential(\n",
       "    (0): Conv2d(256, 256, kernel_size=(3, 6), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "  )\n",
       "  (linear1): Linear(in_features=1024, out_features=256, bias=True)\n",
       "  (rnn1): GRU(256, 256, batch_first=True, bidirectional=True)\n",
       "  (rnn2): GRU(256, 256, batch_first=True, bidirectional=True)\n",
       "  (linear2): Linear(in_features=512, out_features=35, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = CRNN(num_chars=len(char2idx), rnn_hidden_size=256, dropout=0.1)\n",
    "\n",
    "model.load_state_dict(torch.load('crnn_no_chinese_model.pth'))\n",
    "model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de6f5dfa01a54d1fbfae13ce2224dc39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>actual</th>\n",
       "      <th>prediction</th>\n",
       "      <th>prediction_corrected</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AY6F46</td>\n",
       "      <td>YYYY664446</td>\n",
       "      <td>Y646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C096FU</td>\n",
       "      <td>0009996FFU</td>\n",
       "      <td>096FU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C0C9U1</td>\n",
       "      <td>CC00CC9911</td>\n",
       "      <td>C0C91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AY060V</td>\n",
       "      <td>YYYY00000V</td>\n",
       "      <td>Y0V</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ADB398</td>\n",
       "      <td>DDDBBBB998</td>\n",
       "      <td>DB98</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   actual  prediction prediction_corrected\n",
       "0  AY6F46  YYYY664446                 Y646\n",
       "1  C096FU  0009996FFU                096FU\n",
       "2  C0C9U1  CC00CC9911                C0C91\n",
       "3  AY060V  YYYY00000V                  Y0V\n",
       "4  ADB398  DDDBBBB998                 DB98"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def decode_predictions(text_batch_logits):\n",
    "\n",
    "    text_batch_tokens = F.softmax(text_batch_logits, 2).argmax(2) # [T, batch_size]\n",
    "    text_batch_tokens = text_batch_tokens.numpy().T # [batch_size, T]\n",
    "\n",
    "    text_batch_tokens_new = []\n",
    "    for text_tokens in text_batch_tokens:\n",
    "        text = [idx2char[idx] for idx in text_tokens]\n",
    "        text = \"\".join(text)\n",
    "        text_batch_tokens_new.append(text)\n",
    "\n",
    "    return text_batch_tokens_new\n",
    "\n",
    "def remove_duplicates(text):\n",
    "    if len(text) > 1:\n",
    "        letters = [text[0]] + [letter for idx, letter in enumerate(text[1:], start=1) if text[idx] != text[idx-1]]\n",
    "    elif len(text) == 1:\n",
    "        letters = [text[0]]\n",
    "    else:\n",
    "        return \"\"\n",
    "    return \"\".join(letters)\n",
    "\n",
    "def correct_prediction(word):\n",
    "    parts = word.split(\"-\")\n",
    "    parts = [remove_duplicates(part) for part in parts]\n",
    "    corrected_word = \"\".join(parts)\n",
    "    return corrected_word\n",
    "\n",
    "results_val = pd.DataFrame(columns=['actual', 'prediction'])\n",
    "val_loader = DataLoader(valset, batch_size=16, num_workers=0, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for image_batch, text_batch in tqdm(val_loader, leave=True):\n",
    "        text_batch_logits = model(image_batch) # [T, batch_size, num_classes==num_features]\n",
    "        text_batch_pred = decode_predictions(text_batch_logits.cpu())\n",
    "        #print(text_batch, text_batch_pred)\n",
    "        df = pd.DataFrame(columns=['actual', 'prediction'])\n",
    "        df['actual'] = text_batch\n",
    "        df['prediction'] = text_batch_pred\n",
    "        results_val = pd.concat([results_val, df])\n",
    "results_val = results_val.reset_index(drop=True)\n",
    "results_val['prediction_corrected'] = results_val['prediction'].apply(correct_prediction)\n",
    "results_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02\n"
     ]
    }
   ],
   "source": [
    "train_accuracy = accuracy_score(results_val['actual'], results_val['prediction_corrected'])\n",
    "print(train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Y646\n",
       "1       096FU\n",
       "2       C0C91\n",
       "3         Y0V\n",
       "4        DB98\n",
       "        ...  \n",
       "245      L167\n",
       "246      UL12\n",
       "247     FJ956\n",
       "248      S61Z\n",
       "249    BRTW97\n",
       "Name: prediction_corrected, Length: 250, dtype: object"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_val['prediction_corrected']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if (results_val['prediction_corrected'][0][0] == results_val['actual'][0][1]):\n",
    "    print(\"yes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7491428571428571\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for i in range(250):\n",
    "    for j in range(6):\n",
    "    \n",
    "        for k in range(len(results_val['prediction_corrected'][i])):\n",
    "        \n",
    "            if(results_val['actual'][i][j] == results_val['prediction_corrected'][i][k]):\n",
    "                count = count + 1\n",
    "print(count/1750)                \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
