{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader,random_split\n",
    "from torchvision import transforms, datasets, models\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:18<00:00,  3.74it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: training accuracy: 0.2238667900092507, valid accuracy: 0.2066115702479339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.69it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: training accuracy: 0.4588344125809436, valid accuracy: 0.4132231404958678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:15<00:00,  4.37it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: training accuracy: 0.599444958371878, valid accuracy: 0.48760330578512395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.72it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: training accuracy: 0.6558741905642923, valid accuracy: 0.4214876033057851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:13<00:00,  4.94it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: training accuracy: 0.7456059204440333, valid accuracy: 0.4132231404958678\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:13<00:00,  5.15it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: training accuracy: 0.8020351526364478, valid accuracy: 0.512396694214876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.27it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: training accuracy: 0.8316373728029602, valid accuracy: 0.5371900826446281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.38it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: training accuracy: 0.8917668825161887, valid accuracy: 0.49586776859504134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.55it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: training accuracy: 0.9158186864014801, valid accuracy: 0.6198347107438017\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.71it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: training accuracy: 0.9222941720629048, valid accuracy: 0.47107438016528924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.63it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: training accuracy: 0.9167437557816837, valid accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.71it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: training accuracy: 0.9463459759481961, valid accuracy: 0.5619834710743802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.55it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: training accuracy: 0.9380203515263644, valid accuracy: 0.5041322314049587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.55it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: training accuracy: 0.9343200740055504, valid accuracy: 0.6115702479338843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.24it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: training accuracy: 0.9629972247918593, valid accuracy: 0.5702479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:14<00:00,  4.78it/s]\n",
      "100%|██████████| 8/8 [00:07<00:00,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: training accuracy: 0.9500462534690102, valid accuracy: 0.5619834710743802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bird_model = models.resnet18()\n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,120)\n",
    "bird_model.load_state_dict(torch.load('RestNet18_dog_model.pt'))\n",
    "\n",
    "# for param in bird_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "ct = 0\n",
    "for child in bird_model.children():\n",
    "    ct += 1\n",
    "    if ct <= 5:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,25)\n",
    "\n",
    "for param in bird_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bird_model = bird_model.to(device)\n",
    "\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465] \n",
    "std = [0.2470, 0.2435, 0.2616] \n",
    "batch_size = 16\n",
    "n_epochs = 100\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "transforms.Resize((224,224)), \n",
    "transforms.RandomCrop(224, padding=4), \n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.ToTensor(), \n",
    "transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "path='C:/Users/User/DeepLearning/Deep_Learning/Bird_Classification/HW2_Dataset/dataset_new'\n",
    "all_train = datasets.ImageFolder(root = path, transform = train_transform)\n",
    "train_size = int(0.9 * len(all_train ))\n",
    "validation_size = len(all_train) - train_size\n",
    "train_dataset, validation_dataset = random_split(all_train , [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bird_model.parameters(), lr=1e-3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad() # step 1\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        logits = model(images) # step 2 (forward pass)\n",
    "        loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        corrects += predictions.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        loss.backward() # step 4 (backpropagation)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "       \n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    \n",
    "    return train_loss, corrects/total    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, valid_loader, loss_fn):\n",
    "    model.eval()\n",
    "    losses=0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "                \n",
    "            logits = model(images) # step 2 (forward pass)\n",
    "            loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            corrects += predictions.eq(labels).sum().item()\n",
    "            \n",
    "            losses += loss.item()*images.size(0)    \n",
    "            \n",
    "        valid_loss = losses/len(valid_loader.sampler)\n",
    "    return valid_loss, corrects / total\n",
    "\n",
    "\n",
    "# is_valid_available = True\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.9 ** epoch)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=7)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss, training_accuracy = train(bird_model, train_loader, optimizer, loss_fn)\n",
    "    valid_loss, valid_accuracy = validate(bird_model, val_loader, loss_fn)\n",
    "    \n",
    "    train_loss_list.append(training_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    # if scheduler is not None and is_valid_available:\n",
    "    #     scheduler.step(valid_loss)\n",
    "    # elif scheduler is not None:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}: training accuracy: {training_accuracy}, valid accuracy: {valid_accuracy}\")\n",
    "    \n",
    "    if early_stopper.early_stop(valid_loss): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.55it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: training accuracy: 0.17853839037927843, valid accuracy: 0.32231404958677684\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.02it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: training accuracy: 0.43478260869565216, valid accuracy: 0.2644628099173554\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.01it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: training accuracy: 0.5420906567992599, valid accuracy: 0.49586776859504134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.06it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: training accuracy: 0.6410730804810361, valid accuracy: 0.512396694214876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.07it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: training accuracy: 0.7372802960222017, valid accuracy: 0.5702479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.06it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: training accuracy: 0.7946345975948196, valid accuracy: 0.4380165289256198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.09it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: training accuracy: 0.8408880666049954, valid accuracy: 0.48760330578512395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.05it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: training accuracy: 0.8667900092506938, valid accuracy: 0.5041322314049587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.04it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: training accuracy: 0.9111933395004626, valid accuracy: 0.49586776859504134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.01it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: training accuracy: 0.9518963922294172, valid accuracy: 0.5537190082644629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.03it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: training accuracy: 0.9592969472710453, valid accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.00it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: training accuracy: 0.9463459759481961, valid accuracy: 0.5702479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bird_model = models.resnet18()\n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,120)\n",
    "bird_model.load_state_dict(torch.load('RestNet18_dog_model.pt'))\n",
    "\n",
    "# for param in bird_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "ct = 0\n",
    "for child in bird_model.children():\n",
    "    ct += 1\n",
    "    if ct <= 6:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,25)\n",
    "\n",
    "for param in bird_model.fc.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bird_model = bird_model.to(device)\n",
    "\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465] \n",
    "std = [0.2470, 0.2435, 0.2616] \n",
    "batch_size = 16\n",
    "n_epochs = 100\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "transforms.Resize((224,224)), \n",
    "transforms.RandomCrop(224, padding=4), \n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.ToTensor(), \n",
    "transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "path='C:/Users/User/DeepLearning/Deep_Learning/Bird_Classification/HW2_Dataset/dataset_new'\n",
    "all_train = datasets.ImageFolder(root = path, transform = train_transform)\n",
    "train_size = int(0.9 * len(all_train ))\n",
    "validation_size = len(all_train) - train_size\n",
    "train_dataset, validation_dataset = random_split(all_train , [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bird_model.parameters(), lr=1e-3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad() # step 1\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        logits = model(images) # step 2 (forward pass)\n",
    "        loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        corrects += predictions.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        loss.backward() # step 4 (backpropagation)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "       \n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    \n",
    "    return train_loss, corrects/total    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, valid_loader, loss_fn):\n",
    "    model.eval()\n",
    "    losses=0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "                \n",
    "            logits = model(images) # step 2 (forward pass)\n",
    "            loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            corrects += predictions.eq(labels).sum().item()\n",
    "            \n",
    "            losses += loss.item()*images.size(0)    \n",
    "            \n",
    "        valid_loss = losses/len(valid_loader.sampler)\n",
    "    return valid_loss, corrects / total\n",
    "\n",
    "\n",
    "# is_valid_available = True\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.9 ** epoch)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=7)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss, training_accuracy = train(bird_model, train_loader, optimizer, loss_fn)\n",
    "    valid_loss, valid_accuracy = validate(bird_model, val_loader, loss_fn)\n",
    "    \n",
    "    train_loss_list.append(training_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    # if scheduler is not None and is_valid_available:\n",
    "    #     scheduler.step(valid_loss)\n",
    "    # elif scheduler is not None:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}: training accuracy: {training_accuracy}, valid accuracy: {valid_accuracy}\")\n",
    "    \n",
    "    if early_stopper.early_stop(valid_loss): \n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:12<00:00,  5.53it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100: training accuracy: 0.19611470860314523, valid accuracy: 0.2066115702479339\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.00it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/100: training accuracy: 0.40980573543015725, valid accuracy: 0.35537190082644626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.98it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/100: training accuracy: 0.5541165587419057, valid accuracy: 0.4214876033057851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.96it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/100: training accuracy: 0.6207215541165587, valid accuracy: 0.4628099173553719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.05it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/100: training accuracy: 0.7215541165587419, valid accuracy: 0.4380165289256198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.90it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/100: training accuracy: 0.8103607770582794, valid accuracy: 0.5041322314049587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.93it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/100: training accuracy: 0.8399629972247918, valid accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.95it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/100: training accuracy: 0.8908418131359852, valid accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.00it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/100: training accuracy: 0.8889916743755781, valid accuracy: 0.5537190082644629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.98it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100: training accuracy: 0.9352451433857539, valid accuracy: 0.5619834710743802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.01it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/100: training accuracy: 0.9500462534690102, valid accuracy: 0.6033057851239669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.84it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/100: training accuracy: 0.9666975023126735, valid accuracy: 0.6363636363636364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.95it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/100: training accuracy: 0.9565217391304348, valid accuracy: 0.5702479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.94it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/100: training accuracy: 0.9759481961147086, valid accuracy: 0.5702479338842975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.90it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/100: training accuracy: 0.9861239592969473, valid accuracy: 0.6033057851239669\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.92it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/100: training accuracy: 0.9953746530989824, valid accuracy: 0.6694214876033058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.96it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/100: training accuracy: 0.9944495837187789, valid accuracy: 0.4380165289256198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.01it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/100: training accuracy: 0.9833487511563367, valid accuracy: 0.6611570247933884\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  6.01it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/100: training accuracy: 0.9879740980573543, valid accuracy: 0.5454545454545454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.97it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/100: training accuracy: 0.9916743755781684, valid accuracy: 0.6115702479338843\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.96it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/100: training accuracy: 0.9805735430157262, valid accuracy: 0.5289256198347108\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.95it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/100: training accuracy: 0.9925994449583718, valid accuracy: 0.5619834710743802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 68/68 [00:11<00:00,  5.97it/s]\n",
      "100%|██████████| 8/8 [00:06<00:00,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/100: training accuracy: 0.9898242368177613, valid accuracy: 0.5785123966942148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "bird_model = models.resnet18()\n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,120)\n",
    "bird_model.load_state_dict(torch.load('RestNet18_dog_model.pt'))\n",
    "\n",
    "# for param in bird_model.parameters():\n",
    "#     param.requires_grad = False\n",
    "ct = 0\n",
    "for child in bird_model.children():\n",
    "    ct += 1\n",
    "    if ct <= 6:\n",
    "        for param in child.parameters():\n",
    "            param.requires_grad = False\n",
    "    \n",
    "bird_model.fc=nn.Linear(bird_model.fc.in_features,25)\n",
    "\n",
    "for param in bird_model.fc.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "bird_model = bird_model.to(device)\n",
    "\n",
    "\n",
    "mean = [0.4914, 0.4822, 0.4465] \n",
    "std = [0.2470, 0.2435, 0.2616] \n",
    "batch_size = 16\n",
    "n_epochs = 100\n",
    "\n",
    "train_transform = transforms.Compose([ \n",
    "transforms.Resize((224,224)), \n",
    "transforms.RandomCrop(224, padding=4), \n",
    "transforms.RandomHorizontalFlip(),\n",
    "transforms.ToTensor(), \n",
    "transforms.Normalize(mean, std)\n",
    "])\n",
    "\n",
    "path='C:/Users/User/DeepLearning/Deep_Learning/Bird_Classification/HW2_Dataset/dataset_new'\n",
    "all_train = datasets.ImageFolder(root = path, transform = train_transform)\n",
    "train_size = int(0.9 * len(all_train ))\n",
    "validation_size = len(all_train) - train_size\n",
    "train_dataset, validation_dataset = random_split(all_train , [train_size, validation_size])\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    validation_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=3\n",
    ")\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(bird_model.parameters(), lr=1e-3)\n",
    "\n",
    "class EarlyStopper:\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = np.inf\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "def train(model, train_loader, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    train_loss = 0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    for images, labels in tqdm(train_loader):\n",
    "        optimizer.zero_grad() # step 1\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "\n",
    "        logits = model(images) # step 2 (forward pass)\n",
    "        loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "        _, predictions = torch.max(logits, dim=1)\n",
    "        corrects += predictions.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "        \n",
    "        loss.backward() # step 4 (backpropagation)\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "       \n",
    "        \n",
    "    train_loss = train_loss/len(train_loader.sampler)\n",
    "    \n",
    "    return train_loss, corrects/total    \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model, valid_loader, loss_fn):\n",
    "    model.eval()\n",
    "    losses=0.\n",
    "    corrects=0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(val_loader):\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "                \n",
    "            logits = model(images) # step 2 (forward pass)\n",
    "            loss = loss_fn(logits, labels) # step 3 (compute loss)\n",
    "            total += labels.size(0)\n",
    "            \n",
    "            _, predictions = torch.max(logits, dim=1)\n",
    "            corrects += predictions.eq(labels).sum().item()\n",
    "            \n",
    "            losses += loss.item()*images.size(0)    \n",
    "            \n",
    "        valid_loss = losses/len(valid_loader.sampler)\n",
    "    return valid_loss, corrects / total\n",
    "\n",
    "\n",
    "# is_valid_available = True\n",
    "# scheduler = lr_scheduler.LambdaLR(optimizer, lambda epoch: 0.9 ** epoch)\n",
    "# scheduler = lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n",
    "# scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=20, eta_min=0)\n",
    "\n",
    "train_loss_list = []\n",
    "valid_loss_list = []\n",
    "\n",
    "early_stopper = EarlyStopper(patience=7)\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    training_loss, training_accuracy = train(bird_model, train_loader, optimizer, loss_fn)\n",
    "    valid_loss, valid_accuracy = validate(bird_model, val_loader, loss_fn)\n",
    "    \n",
    "    train_loss_list.append(training_loss)\n",
    "    valid_loss_list.append(valid_loss)\n",
    "\n",
    "    # if scheduler is not None and is_valid_available:\n",
    "    #     scheduler.step(valid_loss)\n",
    "    # elif scheduler is not None:\n",
    "    #     scheduler.step()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{n_epochs}: training accuracy: {training_accuracy}, valid accuracy: {valid_accuracy}\")\n",
    "    \n",
    "    if early_stopper.early_stop(valid_loss): \n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
